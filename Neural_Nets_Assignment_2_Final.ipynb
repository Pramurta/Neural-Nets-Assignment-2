{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Nets Assignment 2_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMThqH/QU6NKnS0hXirT9R7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pramurta/Neural-Nets-Assignment-2/blob/main/Neural_Nets_Assignment_2_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GrOvC5SaTmN"
      },
      "source": [
        "!wget -cq http://opensurfaces.cs.cornell.edu/static/minc/minc-2500.tar.gz "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIeumuQmox1X"
      },
      "source": [
        "import tarfile\n",
        "tar = tarfile.open(\"minc-2500.tar.gz\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Bwoj_mpHzr"
      },
      "source": [
        "original_images_dir = '/content/minc-2500/images'\n",
        "sub_dirs = ['metal', 'glass', 'fabric', 'leather', 'paper', 'stone', 'wood', 'plastic', 'water', 'foliage']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcnlSL0opa7O"
      },
      "source": [
        "import os\n",
        "train_dir = '/content/train'\n",
        "val_dir = '/content/val'\n",
        "for sub_dir in sub_dirs:\n",
        "    os.makedirs(train_dir+\"/\"+sub_dir, exist_ok=True)\n",
        "for sub_dir in sub_dirs:\n",
        "    os.makedirs(val_dir+\"/\"+sub_dir, exist_ok=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2afOrtJxppq4"
      },
      "source": [
        "import cv2\n",
        "for sub_dir in sub_dirs:\n",
        "    cur_folder = original_images_dir+\"/\"+sub_dir\n",
        "    for i,filename in enumerate(os.listdir(cur_folder)):\n",
        "        img = cv2.imread(cur_folder+\"/\"+filename)\n",
        "        if i>1999:\n",
        "            cv2.imwrite(val_dir+\"/\"+sub_dir+\"/\"+filename, img)\n",
        "        else:\n",
        "            cv2.imwrite(train_dir+\"/\"+sub_dir+\"/\"+filename, img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD66wxZGqBaf",
        "outputId": "6b1b73e7-e022-4cf5-a667-1ade98497662"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255 and image augmentation has also been used to reduce variance in our training\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      zoom_range=0.3,\n",
        "      horizontal_flip=True,\n",
        "      brightness_range=[0.4,1.5],\n",
        "      fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 140 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/train/',  # This is the source directory for training images\n",
        "        target_size=(150, 150),\n",
        "        batch_size=64,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Flow validation images in batches of 30 using validation_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/val/',  # This is the source directory for validation images\n",
        "        target_size=(150, 150),  \n",
        "        batch_size=64,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 images belonging to 10 classes.\n",
            "Found 5000 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J2q1Vvhqj-V",
        "outputId": "719663f1-1885-4e91-c5ca-4baca8238cfe"
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "#Employing transfer learning by utilizing the pretrained weights of Inception V3 model up to layer \"mixed9\" trained on the imagenet dataset \n",
        "pre_trained_model_inception = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = \"imagenet\")\n",
        "\n",
        "\n",
        "for layer in pre_trained_model_inception.layers:\n",
        "    layer.trainable = False\n",
        "  \n",
        "\n",
        "last_layer = pre_trained_model_inception.get_layer('mixed9')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n",
            "last layer output shape:  (None, 3, 3, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o61bG7aOqpl0"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 8192 hidden units and ReLU activation\n",
        "x = layers.Dense(8192, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# Add a fully connected layer with 2048 hidden units and ReLU activation   \n",
        "x = layers.Dense(2048, activation='relu')(x) \n",
        " # Add a dropout rate of 0.1\n",
        "x = layers.Dropout(0.1)(x) \n",
        "x = layers.Dense(512, activation='relu')(x)           \n",
        "# Add a final softmax layer for classification\n",
        "x = layers.Dense(10, activation='softmax')(x)           \n",
        "\n",
        "model = Model(pre_trained_model_inception.input, x) \n",
        "\n",
        "opt = Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer = opt, \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVQC6uQ4quUQ",
        "outputId": "26bb1d0e-9cf5-4888-8bfc-6f4d19bd6169"
      },
      "source": [
        "history = model.fit(train_generator, epochs=100, steps_per_epoch=313, validation_data = validation_generator, verbose = 1, validation_steps=79)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "199/313 [==================>...........] - ETA: 7:55 - loss: 1.4634 - accuracy: 0.5961"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhLS7Whzqyog"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}