{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgqeiBrYbjTc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd_QE_GEat24"
      },
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Activation,BatchNormalization, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# import keras.backend as K\n",
        "# K.set_image_data_format(‘channels_last’)\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMd1Xeecay36"
      },
      "source": [
        "!wget -cq http://opensurfaces.cs.cornell.edu/static/minc/minc-2500.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBHZNEJXa0wf"
      },
      "source": [
        "import tarfile\n",
        "tar = tarfile.open(\"minc-2500.tar.gz\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARpNJt3sa2t5"
      },
      "source": [
        "original_images_dir = '/content/minc-2500/images'\n",
        "sub_dirs = ['metal', 'glass', 'fabric', 'leather', 'paper', 'stone', 'wood', 'plastic', 'water', 'foliage']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1yUW9LIa4MI"
      },
      "source": [
        "import os\n",
        "train_dir = '/content/train'\n",
        "val_dir = '/content/val'\n",
        "for sub_dir in sub_dirs:\n",
        "    os.makedirs(train_dir+\"/\"+sub_dir, exist_ok=True)\n",
        "for sub_dir in sub_dirs:\n",
        "    os.makedirs(val_dir+\"/\"+sub_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEcGXPbba7AM"
      },
      "source": [
        "import cv2\n",
        "for sub_dir in sub_dirs:\n",
        "    cur_folder = original_images_dir+\"/\"+sub_dir\n",
        "    for i,filename in enumerate(os.listdir(cur_folder)):\n",
        "        img = cv2.imread(cur_folder+\"/\"+filename)\n",
        "        if i>1999:\n",
        "            cv2.imwrite(val_dir+\"/\"+sub_dir+\"/\"+filename, img)\n",
        "        else:\n",
        "            cv2.imwrite(train_dir+\"/\"+sub_dir+\"/\"+filename, img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZzKzC8Fa9Q7",
        "outputId": "a9539ddd-a2ca-4392-cbfd-0ba90014a526"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255 and image augmentation has also been used to reduce variance in our training\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True,\n",
        "      rotation_range=20,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 140 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/train/',  # This is the source directory for training images\n",
        "        target_size=(150, 150),\n",
        "        batch_size=256,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Flow validation images in batches of 30 using validation_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/val/',  # This is the source directory for validation images\n",
        "        target_size=(150, 150),  \n",
        "        batch_size=256,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 images belonging to 10 classes.\n",
            "Found 5000 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lchu3nwXbAMs"
      },
      "source": [
        "import os\n",
        "#tf.keras.backend.clear_session()\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from keras.layers import Dropout\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUUWPKyhd5XX"
      },
      "source": [
        "from keras.layers import Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKUwp5ebbAwa"
      },
      "source": [
        "def AlexNet(input_shape):\n",
        "    \n",
        "  X_input = Input(input_shape)\n",
        "  x_dropout = Dropout(0.3)(X_input)\n",
        "  X = Conv2D(96,(11,11),strides = 4,name=\"conv0\")(x_dropout)\n",
        "  X = BatchNormalization(axis = 3 , name = \"bn0\")(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = MaxPooling2D((3,3),strides = 2,name = 'max0')(X)\n",
        "\n",
        "  X = Conv2D(256,(5,5),padding = 'same' , name = 'conv1')(X)\n",
        "  X = BatchNormalization(axis = 3 ,name='bn1')(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = MaxPooling2D((3,3),strides = 2,name = 'max1')(X)\n",
        "\n",
        "  X = Conv2D(384, (3,3) , padding = 'same' , name='conv2')(X)\n",
        "  X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
        "  X = Activation('relu')(X)\n",
        "  \n",
        "  X = Conv2D(384, (3,3) , padding = 'same' , name='conv3')(X)\n",
        "  X = BatchNormalization(axis = 3, name = 'bn3')(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = Conv2D(256, (3,3) , padding = 'same' , name='conv4')(X)\n",
        "  X = BatchNormalization(axis = 3, name = 'bn4')(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = MaxPooling2D((3,3),strides = 2,name = 'max2')(X)\n",
        "\n",
        "  X = Flatten()(X)\n",
        "\n",
        "  X = Dense(4096, activation = 'relu', name = \"fc0\")(X)\n",
        "\n",
        "  X = Dense(4096, activation = 'relu', name = 'fc1')(X) \n",
        "\n",
        "  X = Dense(10 ,activation='softmax',name = 'fc2')(X)\n",
        "\n",
        "  model = Model(inputs = X_input, outputs = X, name='AlexNet')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnH19K_xbMlB",
        "outputId": "ff6b99ce-fba8-4d32-d3d9-70725a111c97"
      },
      "source": [
        "alex = AlexNet(train_generator[0][0].shape[1:])\n",
        "alex.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"AlexNet\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv0 (Conv2D)               (None, 35, 35, 96)        34944     \n",
            "_________________________________________________________________\n",
            "bn0 (BatchNormalization)     (None, 35, 35, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 35, 35, 96)        0         \n",
            "_________________________________________________________________\n",
            "max0 (MaxPooling2D)          (None, 17, 17, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 17, 17, 256)       614656    \n",
            "_________________________________________________________________\n",
            "bn1 (BatchNormalization)     (None, 17, 17, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "max1 (MaxPooling2D)          (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 8, 8, 384)         885120    \n",
            "_________________________________________________________________\n",
            "bn2 (BatchNormalization)     (None, 8, 8, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 8, 8, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 8, 8, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "bn3 (BatchNormalization)     (None, 8, 8, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8, 8, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 8, 8, 256)         884992    \n",
            "_________________________________________________________________\n",
            "bn4 (BatchNormalization)     (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "max2 (MaxPooling2D)          (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "fc0 (Dense)                  (None, 4096)              9441280   \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 30,016,266\n",
            "Trainable params: 30,013,514\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsGO3ZGhjalK"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdoYHqlgjYna"
      },
      "source": [
        "checkpoint_filepath = '/content/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I2TdQG6bP4w"
      },
      "source": [
        "alex.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO9xHFBbbTBC",
        "outputId": "f99a63b3-33f1-43b6-c1e8-68bcd6983271"
      },
      "source": [
        "alex.fit(train_generator, epochs=100, steps_per_epoch=79, validation_data = validation_generator, verbose = 1, validation_steps=20, callbacks=[model_checkpoint_callback, early_stopping_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "79/79 [==============================] - 207s 2s/step - loss: 3.6558 - accuracy: 0.1310 - val_loss: 4.8396 - val_accuracy: 0.1108\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 176s 2s/step - loss: 2.2720 - accuracy: 0.1421 - val_loss: 2.3504 - val_accuracy: 0.1578\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 177s 2s/step - loss: 2.2235 - accuracy: 0.1734 - val_loss: 2.3032 - val_accuracy: 0.1622\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 178s 2s/step - loss: 2.0854 - accuracy: 0.2294 - val_loss: 2.4208 - val_accuracy: 0.1736\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 178s 2s/step - loss: 2.0207 - accuracy: 0.2627 - val_loss: 2.3604 - val_accuracy: 0.2022\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 176s 2s/step - loss: 1.9775 - accuracy: 0.2844 - val_loss: 2.1996 - val_accuracy: 0.2230\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 178s 2s/step - loss: 1.9343 - accuracy: 0.3083 - val_loss: 1.9479 - val_accuracy: 0.2950\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 178s 2s/step - loss: 1.8991 - accuracy: 0.3243 - val_loss: 1.9773 - val_accuracy: 0.3010\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 174s 2s/step - loss: 1.8622 - accuracy: 0.3456 - val_loss: 1.8934 - val_accuracy: 0.3236\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 176s 2s/step - loss: 1.8341 - accuracy: 0.3557 - val_loss: 1.9369 - val_accuracy: 0.3172\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 176s 2s/step - loss: 1.8167 - accuracy: 0.3632 - val_loss: 2.2069 - val_accuracy: 0.2532\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 176s 2s/step - loss: 1.7872 - accuracy: 0.3751 - val_loss: 1.8738 - val_accuracy: 0.3688\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 178s 2s/step - loss: 1.7675 - accuracy: 0.3802 - val_loss: 1.7788 - val_accuracy: 0.3730\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 178s 2s/step - loss: 1.7437 - accuracy: 0.3895 - val_loss: 2.0279 - val_accuracy: 0.3268\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 173s 2s/step - loss: 1.7118 - accuracy: 0.3979 - val_loss: 1.8225 - val_accuracy: 0.3594\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 173s 2s/step - loss: 1.7016 - accuracy: 0.4060 - val_loss: 2.0772 - val_accuracy: 0.2994\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 174s 2s/step - loss: 1.6776 - accuracy: 0.4169 - val_loss: 1.9854 - val_accuracy: 0.3198\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 174s 2s/step - loss: 1.6523 - accuracy: 0.4229 - val_loss: 1.8239 - val_accuracy: 0.3930\n",
            "Epoch 19/100\n",
            "79/79 [==============================] - 171s 2s/step - loss: 1.6584 - accuracy: 0.4234 - val_loss: 2.0172 - val_accuracy: 0.3310\n",
            "Epoch 20/100\n",
            "79/79 [==============================] - 171s 2s/step - loss: 1.6406 - accuracy: 0.4275 - val_loss: 2.0658 - val_accuracy: 0.3370\n",
            "Epoch 21/100\n",
            "79/79 [==============================] - 171s 2s/step - loss: 1.6145 - accuracy: 0.4397 - val_loss: 1.9561 - val_accuracy: 0.3192\n",
            "Epoch 22/100\n",
            "79/79 [==============================] - 172s 2s/step - loss: 1.6095 - accuracy: 0.4417 - val_loss: 2.0593 - val_accuracy: 0.3158\n",
            "Epoch 23/100\n",
            "79/79 [==============================] - 173s 2s/step - loss: 1.5839 - accuracy: 0.4527 - val_loss: 1.8874 - val_accuracy: 0.3442\n",
            "Epoch 24/100\n",
            "79/79 [==============================] - 174s 2s/step - loss: 1.5848 - accuracy: 0.4506 - val_loss: 1.7700 - val_accuracy: 0.4052\n",
            "Epoch 25/100\n",
            "79/79 [==============================] - 172s 2s/step - loss: 1.5723 - accuracy: 0.4518 - val_loss: 2.1118 - val_accuracy: 0.3150\n",
            "Epoch 26/100\n",
            "79/79 [==============================] - 171s 2s/step - loss: 1.5482 - accuracy: 0.4633 - val_loss: 2.0768 - val_accuracy: 0.3374\n",
            "Epoch 27/100\n",
            "79/79 [==============================] - 172s 2s/step - loss: 1.5449 - accuracy: 0.4658 - val_loss: 1.9890 - val_accuracy: 0.3394\n",
            "Epoch 28/100\n",
            "79/79 [==============================] - 171s 2s/step - loss: 1.5312 - accuracy: 0.4679 - val_loss: 2.3555 - val_accuracy: 0.2848\n",
            "Epoch 29/100\n",
            "79/79 [==============================] - 171s 2s/step - loss: 1.5238 - accuracy: 0.4716 - val_loss: 1.8404 - val_accuracy: 0.3654\n",
            "Epoch 30/100\n",
            "79/79 [==============================] - 171s 2s/step - loss: 1.5162 - accuracy: 0.4710 - val_loss: 2.1106 - val_accuracy: 0.2992\n",
            "Epoch 31/100\n",
            "79/79 [==============================] - 171s 2s/step - loss: 1.4983 - accuracy: 0.4780 - val_loss: 1.9321 - val_accuracy: 0.3600\n",
            "Epoch 32/100\n",
            "79/79 [==============================] - 170s 2s/step - loss: 1.4854 - accuracy: 0.4854 - val_loss: 1.9513 - val_accuracy: 0.3562\n",
            "Epoch 33/100\n",
            "35/79 [============>.................] - ETA: 1:24 - loss: 1.4555 - accuracy: 0.4939"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qki3rn9qYSr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}