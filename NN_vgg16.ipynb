{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pramurta/Neural-Nets-Assignment-2/blob/main/NN_vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD66wxZGqBaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "225ea969-d8d1-40ad-a0a3-6cd070a4dc20"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255 and image augmentation has also been used to reduce variance in our training\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      zoom_range=0.3,\n",
        "      horizontal_flip=True,\n",
        "      brightness_range=[0.4,1.5],\n",
        "      fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 140 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'train',  # This is the source directory for training images\n",
        "        target_size=(150, 150),\n",
        "        batch_size=64,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Flow validation images in batches of 30 using validation_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        'val',  # This is the source directory for validation images\n",
        "        target_size=(150, 150),  \n",
        "        batch_size=64,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 images belonging to 10 classes.\n",
            "Found 5000 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhLS7Whzqyog"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D , Dropout\n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "def define_model_vgg16_improvement(image_shape,total_classes):\n",
        "  print(image_shape[2])\n",
        "\n",
        "  model = Sequential()\n",
        "  weight_decay = 0.0005\n",
        "  learning_rate = 0.1\n",
        "  lr_decay = 1e-6\n",
        "  lr_drop = 20\n",
        "  \n",
        "  model.add(Conv2D(64, (3, 3), padding='same',input_shape=image_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(total_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  sgd = keras.optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "  model.compile(optimizer=sgd, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thjsZOh8i4pm"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "def train_model_vgg16(model , train_generator,validation_generator,epochs=10,batch_size=128):\n",
        "  \n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_vgg16_batch_64', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.8, patience = 3, min_lr = 0.00001, verbose = 1 ),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor = 'val_loss' , patience = 15)\n",
        "  ]\n",
        "  history=model.fit(train_generator, epochs = epochs, batch_size = batch_size,callbacks = callbacks, verbose = 1,validation_data = validation_generator)\n",
        "  return history"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xREbRp2AyM0",
        "outputId": "f72affbe-b20c-41bf-f3b1-d1d6b404ea64"
      },
      "source": [
        "improved_model = define_model_vgg16_improvement((150, 150, 3),10)\n",
        "history = train_model_vgg16(improved_model , train_generator , validation_generator , epochs=200 , batch_size = 64)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "Epoch 1/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 63.8692 - accuracy: 0.1690\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.15580, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 327ms/step - loss: 63.8692 - accuracy: 0.1690 - val_loss: 49.5893 - val_accuracy: 0.1558 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 37.3542 - accuracy: 0.2420\n",
            "Epoch 00002: val_accuracy did not improve from 0.15580\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 37.3542 - accuracy: 0.2420 - val_loss: 27.5647 - val_accuracy: 0.1202 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 20.7920 - accuracy: 0.2915\n",
            "Epoch 00003: val_accuracy improved from 0.15580 to 0.17560, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 326ms/step - loss: 20.7920 - accuracy: 0.2915 - val_loss: 16.2408 - val_accuracy: 0.1756 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 12.0260 - accuracy: 0.3183\n",
            "Epoch 00004: val_accuracy improved from 0.17560 to 0.24900, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 326ms/step - loss: 12.0260 - accuracy: 0.3183 - val_loss: 9.3751 - val_accuracy: 0.2490 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 7.4735 - accuracy: 0.3207\n",
            "Epoch 00005: val_accuracy improved from 0.24900 to 0.27200, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 325ms/step - loss: 7.4735 - accuracy: 0.3207 - val_loss: 6.2237 - val_accuracy: 0.2720 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 5.0271 - accuracy: 0.3349\n",
            "Epoch 00006: val_accuracy did not improve from 0.27200\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 5.0271 - accuracy: 0.3349 - val_loss: 4.2915 - val_accuracy: 0.2664 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 3.5819 - accuracy: 0.3620\n",
            "Epoch 00007: val_accuracy improved from 0.27200 to 0.32320, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 103s 328ms/step - loss: 3.5819 - accuracy: 0.3620 - val_loss: 3.2034 - val_accuracy: 0.3232 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 2.8509 - accuracy: 0.3787\n",
            "Epoch 00008: val_accuracy did not improve from 0.32320\n",
            "313/313 [==============================] - 97s 310ms/step - loss: 2.8509 - accuracy: 0.3787 - val_loss: 2.8547 - val_accuracy: 0.2926 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 2.5518 - accuracy: 0.3896\n",
            "Epoch 00009: val_accuracy improved from 0.32320 to 0.36720, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 327ms/step - loss: 2.5518 - accuracy: 0.3896 - val_loss: 2.5161 - val_accuracy: 0.3672 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 2.3381 - accuracy: 0.4098\n",
            "Epoch 00010: val_accuracy improved from 0.36720 to 0.38640, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 326ms/step - loss: 2.3381 - accuracy: 0.4098 - val_loss: 2.3105 - val_accuracy: 0.3864 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 2.1616 - accuracy: 0.4312\n",
            "Epoch 00011: val_accuracy did not improve from 0.38640\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 2.1616 - accuracy: 0.4312 - val_loss: 2.2428 - val_accuracy: 0.3820 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 2.0834 - accuracy: 0.4317\n",
            "Epoch 00012: val_accuracy did not improve from 0.38640\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 2.0834 - accuracy: 0.4317 - val_loss: 2.2711 - val_accuracy: 0.3512 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 2.0351 - accuracy: 0.4416\n",
            "Epoch 00013: val_accuracy improved from 0.38640 to 0.44180, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 103s 328ms/step - loss: 2.0351 - accuracy: 0.4416 - val_loss: 2.0375 - val_accuracy: 0.4418 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 2.0148 - accuracy: 0.4501\n",
            "Epoch 00014: val_accuracy did not improve from 0.44180\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 2.0148 - accuracy: 0.4501 - val_loss: 2.0575 - val_accuracy: 0.4238 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 2.0150 - accuracy: 0.4557\n",
            "Epoch 00015: val_accuracy improved from 0.44180 to 0.45100, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 103s 328ms/step - loss: 2.0150 - accuracy: 0.4557 - val_loss: 2.0278 - val_accuracy: 0.4510 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.9991 - accuracy: 0.4642\n",
            "Epoch 00016: val_accuracy did not improve from 0.45100\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 1.9991 - accuracy: 0.4642 - val_loss: 2.0755 - val_accuracy: 0.4468 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.9925 - accuracy: 0.4663\n",
            "Epoch 00017: val_accuracy did not improve from 0.45100\n",
            "313/313 [==============================] - 98s 313ms/step - loss: 1.9925 - accuracy: 0.4663 - val_loss: 2.2749 - val_accuracy: 0.3950 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.9962 - accuracy: 0.4717\n",
            "Epoch 00018: val_accuracy did not improve from 0.45100\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0800000011920929.\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 1.9962 - accuracy: 0.4717 - val_loss: 2.1091 - val_accuracy: 0.4448 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.9203 - accuracy: 0.4961\n",
            "Epoch 00019: val_accuracy improved from 0.45100 to 0.46480, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 325ms/step - loss: 1.9203 - accuracy: 0.4961 - val_loss: 2.0808 - val_accuracy: 0.4648 - lr: 0.0800\n",
            "Epoch 20/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.8939 - accuracy: 0.5031\n",
            "Epoch 00020: val_accuracy improved from 0.46480 to 0.46660, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 103s 328ms/step - loss: 1.8939 - accuracy: 0.5031 - val_loss: 1.9908 - val_accuracy: 0.4666 - lr: 0.0800\n",
            "Epoch 21/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.9176 - accuracy: 0.5092\n",
            "Epoch 00021: val_accuracy did not improve from 0.46660\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 1.9176 - accuracy: 0.5092 - val_loss: 2.2713 - val_accuracy: 0.3850 - lr: 0.0800\n",
            "Epoch 22/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.9169 - accuracy: 0.5091\n",
            "Epoch 00022: val_accuracy improved from 0.46660 to 0.49000, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 327ms/step - loss: 1.9169 - accuracy: 0.5091 - val_loss: 1.9783 - val_accuracy: 0.4900 - lr: 0.0800\n",
            "Epoch 23/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.9002 - accuracy: 0.5181\n",
            "Epoch 00023: val_accuracy did not improve from 0.49000\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 1.9002 - accuracy: 0.5181 - val_loss: 2.0496 - val_accuracy: 0.4482 - lr: 0.0800\n",
            "Epoch 24/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.9329 - accuracy: 0.5117\n",
            "Epoch 00024: val_accuracy did not improve from 0.49000\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 1.9329 - accuracy: 0.5117 - val_loss: 2.1097 - val_accuracy: 0.4736 - lr: 0.0800\n",
            "Epoch 25/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.9361 - accuracy: 0.5264\n",
            "Epoch 00025: val_accuracy did not improve from 0.49000\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.06399999856948853.\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 1.9361 - accuracy: 0.5264 - val_loss: 2.0630 - val_accuracy: 0.4836 - lr: 0.0800\n",
            "Epoch 26/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.8633 - accuracy: 0.5386\n",
            "Epoch 00026: val_accuracy improved from 0.49000 to 0.51340, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 103s 328ms/step - loss: 1.8633 - accuracy: 0.5386 - val_loss: 1.9475 - val_accuracy: 0.5134 - lr: 0.0640\n",
            "Epoch 27/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.8223 - accuracy: 0.5530\n",
            "Epoch 00027: val_accuracy improved from 0.51340 to 0.51620, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 325ms/step - loss: 1.8223 - accuracy: 0.5530 - val_loss: 1.9350 - val_accuracy: 0.5162 - lr: 0.0640\n",
            "Epoch 28/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.8010 - accuracy: 0.5538\n",
            "Epoch 00028: val_accuracy did not improve from 0.51620\n",
            "313/313 [==============================] - 98s 313ms/step - loss: 1.8010 - accuracy: 0.5538 - val_loss: 1.9681 - val_accuracy: 0.4958 - lr: 0.0640\n",
            "Epoch 29/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.7924 - accuracy: 0.5592\n",
            "Epoch 00029: val_accuracy did not improve from 0.51620\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 1.7924 - accuracy: 0.5592 - val_loss: 1.9954 - val_accuracy: 0.5160 - lr: 0.0640\n",
            "Epoch 30/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.7893 - accuracy: 0.5641\n",
            "Epoch 00030: val_accuracy improved from 0.51620 to 0.54480, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 103s 327ms/step - loss: 1.7893 - accuracy: 0.5641 - val_loss: 1.8503 - val_accuracy: 0.5448 - lr: 0.0640\n",
            "Epoch 31/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.7922 - accuracy: 0.5626\n",
            "Epoch 00031: val_accuracy did not improve from 0.54480\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 1.7922 - accuracy: 0.5626 - val_loss: 2.0104 - val_accuracy: 0.4722 - lr: 0.0640\n",
            "Epoch 32/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.7882 - accuracy: 0.5716\n",
            "Epoch 00032: val_accuracy improved from 0.54480 to 0.56040, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 103s 328ms/step - loss: 1.7882 - accuracy: 0.5716 - val_loss: 1.7836 - val_accuracy: 0.5604 - lr: 0.0640\n",
            "Epoch 33/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.7842 - accuracy: 0.5691\n",
            "Epoch 00033: val_accuracy did not improve from 0.56040\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 1.7842 - accuracy: 0.5691 - val_loss: 1.9797 - val_accuracy: 0.5078 - lr: 0.0640\n",
            "Epoch 34/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.7788 - accuracy: 0.5737\n",
            "Epoch 00034: val_accuracy did not improve from 0.56040\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 1.7788 - accuracy: 0.5737 - val_loss: 1.9407 - val_accuracy: 0.5156 - lr: 0.0640\n",
            "Epoch 35/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.7861 - accuracy: 0.5785\n",
            "Epoch 00035: val_accuracy did not improve from 0.56040\n",
            "\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.05119999647140503.\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 1.7861 - accuracy: 0.5785 - val_loss: 2.0007 - val_accuracy: 0.5124 - lr: 0.0640\n",
            "Epoch 36/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.7268 - accuracy: 0.5972\n",
            "Epoch 00036: val_accuracy improved from 0.56040 to 0.56480, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 326ms/step - loss: 1.7268 - accuracy: 0.5972 - val_loss: 1.8078 - val_accuracy: 0.5648 - lr: 0.0512\n",
            "Epoch 37/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.7050 - accuracy: 0.6016\n",
            "Epoch 00037: val_accuracy improved from 0.56480 to 0.57860, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 103s 329ms/step - loss: 1.7050 - accuracy: 0.6016 - val_loss: 1.7487 - val_accuracy: 0.5786 - lr: 0.0512\n",
            "Epoch 38/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.7060 - accuracy: 0.5984\n",
            "Epoch 00038: val_accuracy did not improve from 0.57860\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 1.7060 - accuracy: 0.5984 - val_loss: 1.8815 - val_accuracy: 0.5304 - lr: 0.0512\n",
            "Epoch 39/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.6918 - accuracy: 0.6069\n",
            "Epoch 00039: val_accuracy did not improve from 0.57860\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 1.6918 - accuracy: 0.6069 - val_loss: 1.8077 - val_accuracy: 0.5750 - lr: 0.0512\n",
            "Epoch 40/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.6964 - accuracy: 0.6102\n",
            "Epoch 00040: val_accuracy did not improve from 0.57860\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.04095999598503113.\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 1.6964 - accuracy: 0.6102 - val_loss: 1.8801 - val_accuracy: 0.5520 - lr: 0.0512\n",
            "Epoch 41/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.6408 - accuracy: 0.6271\n",
            "Epoch 00041: val_accuracy improved from 0.57860 to 0.60860, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 103s 328ms/step - loss: 1.6408 - accuracy: 0.6271 - val_loss: 1.6625 - val_accuracy: 0.6086 - lr: 0.0410\n",
            "Epoch 42/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.6228 - accuracy: 0.6274\n",
            "Epoch 00042: val_accuracy did not improve from 0.60860\n",
            "313/313 [==============================] - 98s 313ms/step - loss: 1.6228 - accuracy: 0.6274 - val_loss: 1.8527 - val_accuracy: 0.5496 - lr: 0.0410\n",
            "Epoch 43/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.6147 - accuracy: 0.6299\n",
            "Epoch 00043: val_accuracy did not improve from 0.60860\n",
            "313/313 [==============================] - 98s 313ms/step - loss: 1.6147 - accuracy: 0.6299 - val_loss: 1.6996 - val_accuracy: 0.6046 - lr: 0.0410\n",
            "Epoch 44/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.6192 - accuracy: 0.6291\n",
            "Epoch 00044: val_accuracy did not improve from 0.60860\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.032767996191978455.\n",
            "313/313 [==============================] - 97s 310ms/step - loss: 1.6192 - accuracy: 0.6291 - val_loss: 1.7540 - val_accuracy: 0.5810 - lr: 0.0410\n",
            "Epoch 45/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.5629 - accuracy: 0.6444\n",
            "Epoch 00045: val_accuracy did not improve from 0.60860\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 1.5629 - accuracy: 0.6444 - val_loss: 1.7739 - val_accuracy: 0.5748 - lr: 0.0328\n",
            "Epoch 46/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.5408 - accuracy: 0.6527\n",
            "Epoch 00046: val_accuracy improved from 0.60860 to 0.63140, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 327ms/step - loss: 1.5408 - accuracy: 0.6527 - val_loss: 1.5920 - val_accuracy: 0.6314 - lr: 0.0328\n",
            "Epoch 47/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.5303 - accuracy: 0.6600\n",
            "Epoch 00047: val_accuracy did not improve from 0.63140\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 1.5303 - accuracy: 0.6600 - val_loss: 1.7617 - val_accuracy: 0.5846 - lr: 0.0328\n",
            "Epoch 48/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.5313 - accuracy: 0.6564\n",
            "Epoch 00048: val_accuracy did not improve from 0.63140\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 1.5313 - accuracy: 0.6564 - val_loss: 1.7537 - val_accuracy: 0.5874 - lr: 0.0328\n",
            "Epoch 49/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.5308 - accuracy: 0.6622\n",
            "Epoch 00049: val_accuracy did not improve from 0.63140\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.026214396953582766.\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 1.5308 - accuracy: 0.6622 - val_loss: 1.7235 - val_accuracy: 0.5972 - lr: 0.0328\n",
            "Epoch 50/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.4882 - accuracy: 0.6760\n",
            "Epoch 00050: val_accuracy did not improve from 0.63140\n",
            "313/313 [==============================] - 97s 310ms/step - loss: 1.4882 - accuracy: 0.6760 - val_loss: 1.6229 - val_accuracy: 0.6268 - lr: 0.0262\n",
            "Epoch 51/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.4708 - accuracy: 0.6783\n",
            "Epoch 00051: val_accuracy improved from 0.63140 to 0.65560, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 325ms/step - loss: 1.4708 - accuracy: 0.6783 - val_loss: 1.5539 - val_accuracy: 0.6556 - lr: 0.0262\n",
            "Epoch 52/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.4606 - accuracy: 0.6848\n",
            "Epoch 00052: val_accuracy did not improve from 0.65560\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 1.4606 - accuracy: 0.6848 - val_loss: 1.6363 - val_accuracy: 0.6246 - lr: 0.0262\n",
            "Epoch 53/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.4634 - accuracy: 0.6819\n",
            "Epoch 00053: val_accuracy did not improve from 0.65560\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 1.4634 - accuracy: 0.6819 - val_loss: 1.6085 - val_accuracy: 0.6394 - lr: 0.0262\n",
            "Epoch 54/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.4658 - accuracy: 0.6851\n",
            "Epoch 00054: val_accuracy did not improve from 0.65560\n",
            "\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.02097151726484299.\n",
            "313/313 [==============================] - 97s 309ms/step - loss: 1.4658 - accuracy: 0.6851 - val_loss: 1.6189 - val_accuracy: 0.6356 - lr: 0.0262\n",
            "Epoch 55/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.4247 - accuracy: 0.6963\n",
            "Epoch 00055: val_accuracy did not improve from 0.65560\n",
            "313/313 [==============================] - 97s 310ms/step - loss: 1.4247 - accuracy: 0.6963 - val_loss: 1.6572 - val_accuracy: 0.6218 - lr: 0.0210\n",
            "Epoch 56/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.4199 - accuracy: 0.7022\n",
            "Epoch 00056: val_accuracy did not improve from 0.65560\n",
            "313/313 [==============================] - 97s 310ms/step - loss: 1.4199 - accuracy: 0.7022 - val_loss: 1.5947 - val_accuracy: 0.6492 - lr: 0.0210\n",
            "Epoch 57/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.3926 - accuracy: 0.7093\n",
            "Epoch 00057: val_accuracy improved from 0.65560 to 0.65720, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.016777214407920838.\n",
            "313/313 [==============================] - 103s 328ms/step - loss: 1.3926 - accuracy: 0.7093 - val_loss: 1.5591 - val_accuracy: 0.6572 - lr: 0.0210\n",
            "Epoch 58/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.3490 - accuracy: 0.7226\n",
            "Epoch 00058: val_accuracy did not improve from 0.65720\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 1.3490 - accuracy: 0.7226 - val_loss: 1.5693 - val_accuracy: 0.6546 - lr: 0.0168\n",
            "Epoch 59/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.3350 - accuracy: 0.7245\n",
            "Epoch 00059: val_accuracy did not improve from 0.65720\n",
            "313/313 [==============================] - 97s 310ms/step - loss: 1.3350 - accuracy: 0.7245 - val_loss: 1.6230 - val_accuracy: 0.6390 - lr: 0.0168\n",
            "Epoch 60/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.3263 - accuracy: 0.7281\n",
            "Epoch 00060: val_accuracy did not improve from 0.65720\n",
            "\n",
            "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.013421770930290223.\n",
            "313/313 [==============================] - 97s 310ms/step - loss: 1.3263 - accuracy: 0.7281 - val_loss: 1.6347 - val_accuracy: 0.6352 - lr: 0.0168\n",
            "Epoch 61/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.2772 - accuracy: 0.7492\n",
            "Epoch 00061: val_accuracy improved from 0.65720 to 0.66520, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 326ms/step - loss: 1.2772 - accuracy: 0.7492 - val_loss: 1.5159 - val_accuracy: 0.6652 - lr: 0.0134\n",
            "Epoch 62/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.2679 - accuracy: 0.7473\n",
            "Epoch 00062: val_accuracy improved from 0.66520 to 0.67500, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 325ms/step - loss: 1.2679 - accuracy: 0.7473 - val_loss: 1.4914 - val_accuracy: 0.6750 - lr: 0.0134\n",
            "Epoch 63/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.2642 - accuracy: 0.7480\n",
            "Epoch 00063: val_accuracy did not improve from 0.67500\n",
            "313/313 [==============================] - 97s 310ms/step - loss: 1.2642 - accuracy: 0.7480 - val_loss: 1.5544 - val_accuracy: 0.6608 - lr: 0.0134\n",
            "Epoch 64/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.2512 - accuracy: 0.7521\n",
            "Epoch 00064: val_accuracy did not improve from 0.67500\n",
            "313/313 [==============================] - 97s 310ms/step - loss: 1.2512 - accuracy: 0.7521 - val_loss: 1.5489 - val_accuracy: 0.6624 - lr: 0.0134\n",
            "Epoch 65/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.2540 - accuracy: 0.7517\n",
            "Epoch 00065: val_accuracy did not improve from 0.67500\n",
            "\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.010737416893243791.\n",
            "313/313 [==============================] - 97s 310ms/step - loss: 1.2540 - accuracy: 0.7517 - val_loss: 1.5379 - val_accuracy: 0.6708 - lr: 0.0134\n",
            "Epoch 66/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.2044 - accuracy: 0.7685\n",
            "Epoch 00066: val_accuracy did not improve from 0.67500\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 1.2044 - accuracy: 0.7685 - val_loss: 1.5744 - val_accuracy: 0.6572 - lr: 0.0107\n",
            "Epoch 67/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.1929 - accuracy: 0.7739\n",
            "Epoch 00067: val_accuracy did not improve from 0.67500\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 1.1929 - accuracy: 0.7739 - val_loss: 1.6591 - val_accuracy: 0.6376 - lr: 0.0107\n",
            "Epoch 68/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.1848 - accuracy: 0.7793\n",
            "Epoch 00068: val_accuracy did not improve from 0.67500\n",
            "\n",
            "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.008589933812618257.\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 1.1848 - accuracy: 0.7793 - val_loss: 1.6175 - val_accuracy: 0.6526 - lr: 0.0107\n",
            "Epoch 69/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.1457 - accuracy: 0.7854\n",
            "Epoch 00069: val_accuracy improved from 0.67500 to 0.68860, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 327ms/step - loss: 1.1457 - accuracy: 0.7854 - val_loss: 1.4985 - val_accuracy: 0.6886 - lr: 0.0086\n",
            "Epoch 70/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.1224 - accuracy: 0.7968\n",
            "Epoch 00070: val_accuracy did not improve from 0.68860\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 1.1224 - accuracy: 0.7968 - val_loss: 1.5226 - val_accuracy: 0.6830 - lr: 0.0086\n",
            "Epoch 71/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.1247 - accuracy: 0.7929\n",
            "Epoch 00071: val_accuracy did not improve from 0.68860\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.006871946901082993.\n",
            "313/313 [==============================] - 97s 310ms/step - loss: 1.1247 - accuracy: 0.7929 - val_loss: 1.5430 - val_accuracy: 0.6848 - lr: 0.0086\n",
            "Epoch 72/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.0723 - accuracy: 0.8144\n",
            "Epoch 00072: val_accuracy improved from 0.68860 to 0.69140, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 101s 324ms/step - loss: 1.0723 - accuracy: 0.8144 - val_loss: 1.5344 - val_accuracy: 0.6914 - lr: 0.0069\n",
            "Epoch 73/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.0462 - accuracy: 0.8195\n",
            "Epoch 00073: val_accuracy improved from 0.69140 to 0.70100, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 103s 328ms/step - loss: 1.0462 - accuracy: 0.8195 - val_loss: 1.5102 - val_accuracy: 0.7010 - lr: 0.0069\n",
            "Epoch 74/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.0459 - accuracy: 0.8214\n",
            "Epoch 00074: val_accuracy did not improve from 0.70100\n",
            "\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0054975576698780065.\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 1.0459 - accuracy: 0.8214 - val_loss: 1.5961 - val_accuracy: 0.6762 - lr: 0.0069\n",
            "Epoch 75/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.0060 - accuracy: 0.8342\n",
            "Epoch 00075: val_accuracy did not improve from 0.70100\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 1.0060 - accuracy: 0.8342 - val_loss: 1.5174 - val_accuracy: 0.6924 - lr: 0.0055\n",
            "Epoch 76/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.9952 - accuracy: 0.8348\n",
            "Epoch 00076: val_accuracy did not improve from 0.70100\n",
            "313/313 [==============================] - 97s 310ms/step - loss: 0.9952 - accuracy: 0.8348 - val_loss: 1.5251 - val_accuracy: 0.7006 - lr: 0.0055\n",
            "Epoch 77/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.9866 - accuracy: 0.8385\n",
            "Epoch 00077: val_accuracy improved from 0.70100 to 0.70340, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 327ms/step - loss: 0.9866 - accuracy: 0.8385 - val_loss: 1.4894 - val_accuracy: 0.7034 - lr: 0.0055\n",
            "Epoch 78/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.9758 - accuracy: 0.8427\n",
            "Epoch 00078: val_accuracy did not improve from 0.70340\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 0.9758 - accuracy: 0.8427 - val_loss: 1.4698 - val_accuracy: 0.7022 - lr: 0.0055\n",
            "Epoch 79/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.9758 - accuracy: 0.8410\n",
            "Epoch 00079: val_accuracy did not improve from 0.70340\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 0.9758 - accuracy: 0.8410 - val_loss: 1.5653 - val_accuracy: 0.6948 - lr: 0.0055\n",
            "Epoch 80/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.9682 - accuracy: 0.8453\n",
            "Epoch 00080: val_accuracy did not improve from 0.70340\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 0.9682 - accuracy: 0.8453 - val_loss: 1.6129 - val_accuracy: 0.6836 - lr: 0.0055\n",
            "Epoch 81/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.9651 - accuracy: 0.8480\n",
            "Epoch 00081: val_accuracy did not improve from 0.70340\n",
            "\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.004398046061396599.\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 0.9651 - accuracy: 0.8480 - val_loss: 1.6482 - val_accuracy: 0.6774 - lr: 0.0055\n",
            "Epoch 82/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.9238 - accuracy: 0.8613\n",
            "Epoch 00082: val_accuracy did not improve from 0.70340\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 0.9238 - accuracy: 0.8613 - val_loss: 1.5458 - val_accuracy: 0.6972 - lr: 0.0044\n",
            "Epoch 83/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.9128 - accuracy: 0.8658\n",
            "Epoch 00083: val_accuracy did not improve from 0.70340\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 0.9128 - accuracy: 0.8658 - val_loss: 1.6005 - val_accuracy: 0.6984 - lr: 0.0044\n",
            "Epoch 84/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.9069 - accuracy: 0.8670\n",
            "Epoch 00084: val_accuracy did not improve from 0.70340\n",
            "\n",
            "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0035184368491172793.\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 0.9069 - accuracy: 0.8670 - val_loss: 1.5909 - val_accuracy: 0.6976 - lr: 0.0044\n",
            "Epoch 85/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.8729 - accuracy: 0.8781\n",
            "Epoch 00085: val_accuracy improved from 0.70340 to 0.71560, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 325ms/step - loss: 0.8729 - accuracy: 0.8781 - val_loss: 1.5155 - val_accuracy: 0.7156 - lr: 0.0035\n",
            "Epoch 86/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.8483 - accuracy: 0.8852\n",
            "Epoch 00086: val_accuracy improved from 0.71560 to 0.71800, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 103s 329ms/step - loss: 0.8483 - accuracy: 0.8852 - val_loss: 1.5315 - val_accuracy: 0.7180 - lr: 0.0035\n",
            "Epoch 87/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.8443 - accuracy: 0.8837\n",
            "Epoch 00087: val_accuracy did not improve from 0.71800\n",
            "\n",
            "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0028147494420409204.\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 0.8443 - accuracy: 0.8837 - val_loss: 1.5131 - val_accuracy: 0.7170 - lr: 0.0035\n",
            "Epoch 88/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.8105 - accuracy: 0.8979\n",
            "Epoch 00088: val_accuracy did not improve from 0.71800\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 0.8105 - accuracy: 0.8979 - val_loss: 1.5837 - val_accuracy: 0.7038 - lr: 0.0028\n",
            "Epoch 89/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.7888 - accuracy: 0.9050\n",
            "Epoch 00089: val_accuracy did not improve from 0.71800\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 0.7888 - accuracy: 0.9050 - val_loss: 1.7798 - val_accuracy: 0.6708 - lr: 0.0028\n",
            "Epoch 90/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.7797 - accuracy: 0.9066\n",
            "Epoch 00090: val_accuracy did not improve from 0.71800\n",
            "\n",
            "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.002251799590885639.\n",
            "313/313 [==============================] - 97s 311ms/step - loss: 0.7797 - accuracy: 0.9066 - val_loss: 1.5724 - val_accuracy: 0.7098 - lr: 0.0028\n",
            "Epoch 91/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.7522 - accuracy: 0.9145\n",
            "Epoch 00091: val_accuracy improved from 0.71800 to 0.72040, saving model to best_model_vgg16_batch_64\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_batch_64/assets\n",
            "313/313 [==============================] - 102s 327ms/step - loss: 0.7522 - accuracy: 0.9145 - val_loss: 1.5601 - val_accuracy: 0.7204 - lr: 0.0023\n",
            "Epoch 92/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.7448 - accuracy: 0.9180\n",
            "Epoch 00092: val_accuracy did not improve from 0.72040\n",
            "313/313 [==============================] - 98s 313ms/step - loss: 0.7448 - accuracy: 0.9180 - val_loss: 1.5510 - val_accuracy: 0.7176 - lr: 0.0023\n",
            "Epoch 93/200\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.7303 - accuracy: 0.9209\n",
            "Epoch 00093: val_accuracy did not improve from 0.72040\n",
            "\n",
            "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0018014397472143175.\n",
            "313/313 [==============================] - 98s 312ms/step - loss: 0.7303 - accuracy: 0.9209 - val_loss: 1.5966 - val_accuracy: 0.7110 - lr: 0.0023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpNAVhAcls4_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "8990826f-3aa7-4a85-a04b-fcaaf3d968f0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (8,5))\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Validation loss history resnet')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot history: Accuracy\n",
        "plt.figure(figsize = (8,5))\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Validation accuracy history resnet')\n",
        "plt.ylabel('Accuracy value (%)')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrxuIAbYpn-U"
      },
      "source": [
        "def identity_block(x, filter):\n",
        "    # copy tensor to variable called x_skip\n",
        "    x_skip = x\n",
        "    # Layer 1\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    # Layer 2\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    # Add Residue\n",
        "    x = tf.keras.layers.Add()([x, x_skip])     \n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def convolutional_block(x, filter):\n",
        "    # copy tensor to variable called x_skip\n",
        "    x_skip = x\n",
        "    # Layer 1\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    # Layer 2\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    # Processing Residue with conv(1,1)\n",
        "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
        "    # Add Residue\n",
        "    x = tf.keras.layers.Add()([x, x_skip])     \n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def ResNet34(shape, classes):\n",
        "    # Step 1 (Setup Input Layer)Created using Colaboratory\n",
        "    x_input = tf.keras.layers.Input(shape)\n",
        "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
        "    # Step 2 (Initial Conv layer along with maxPool)\n",
        "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
        "    # Define size of sub-blocks and initial filter size\n",
        "    block_layers = [3, 4, 6, 3]\n",
        "    filter_size = 64\n",
        "    # Step 3 Add the Resnet Blocks\n",
        "    for i in range(4):\n",
        "        if i == 0:\n",
        "            # For sub-block 1 Residual/Convolutional block not needed\n",
        "            for j in range(block_layers[i]):\n",
        "                x = identity_block(x, filter_size)\n",
        "        else:\n",
        "            # One Residual/Convolutional Block followed by Identity blocks\n",
        "            # The filter size will go on increasing by a factor of 2\n",
        "            filter_size = filter_size*2\n",
        "            x = convolutional_block(x, filter_size)\n",
        "            for j in range(block_layers[i] - 1):\n",
        "                x = identity_block(x, filter_size)\n",
        "    # Step 4 End Dense Network\n",
        "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
        "    x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n",
        "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLSzxZYLmpkC"
      },
      "source": [
        "\n",
        "def train_model_resnet34(model , train_generator,validation_generator,epochs=10,batch_size=64):\n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_resnet34', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.1, patience = 5, min_lr = 0.000001, verbose = 1 ),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor = 'val_loss' , patience = 15)\n",
        "  ]\n",
        "  history=model.fit(train_generator, epochs = epochs , validation_data=validation_generator,batch_size= 128 , callbacks = callbacks)\n",
        "  return history"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GWKt8BrpNp5"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El3OHoCBmuoE"
      },
      "source": [
        "model_resnet=ResNet34((150, 150, 3),10)\n",
        "train_model_resnet34(model_resnet , train_generator , validation_generator , epochs=100 , batch_size = 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nnpk71uCnFF0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}